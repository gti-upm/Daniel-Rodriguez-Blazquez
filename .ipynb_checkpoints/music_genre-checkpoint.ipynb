{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3c266dcff622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Dense, Dropout, Conv1D, Conv2D, Flatten, BatchNormalization, ZeroPadding2D, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "data = pd.read_csv(r'C:\\Users\\Yang Saewon\\Desktop\\project\\myproject\\music_genre\\music_analysis.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_name(i):\n",
    "    if i < 18000:\n",
    "        return '0'\n",
    "    elif i >= 18000 and i < 41000:\n",
    "        return '1'\n",
    "    elif i >= 41000 and i < 57000:\n",
    "        return '2'\n",
    "    elif i >= 57000 and i < 72000:\n",
    "        return '3'\n",
    "    elif i >= 72000 and i < 89000:\n",
    "        return '4'\n",
    "    elif i >= 89000 and i < 108000:\n",
    "        return '5'\n",
    "    elif i >= 108000 and i < 117000:\n",
    "        return '6'\n",
    "    elif i >= 117000 and i < 127000:\n",
    "        return '7'\n",
    "    elif i >= 127000 and i < 138000:\n",
    "        return '8'\n",
    "    else:\n",
    "        return '9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_number(i):\n",
    "    if i == 'Hip-Hop':\n",
    "        return 0\n",
    "    elif i == 'Pop':\n",
    "        return 1\n",
    "    elif i == 'Folk':\n",
    "        return 2\n",
    "    elif i == 'Rock':\n",
    "        return 3\n",
    "    elif i == 'Experimental':\n",
    "        return 4\n",
    "    elif i == 'International':\n",
    "        return 5\n",
    "    elif i == 'Electronic':\n",
    "        return 6\n",
    "    else:\n",
    "        return '7' #instrumental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['genre_number'] = data['genre'].apply(genre_number)\n",
    "data['folder_number'] = data['file_name'].apply(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['file_name'] = data['file_name'].apply(lambda x: '{0:0>6}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['path'] = data['folder_number'].astype('str') + '/' + data['file_name'].astype('str') + \".wav\"\n",
    "data['path'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example of Hip-Hop music\n",
    "y, sr = librosa.load(r'C:\\Users\\Yang Saewon\\Desktop\\project\\myproject\\music_genre\\fma_small\\0/000002.wav', duration=10)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(librosa.power_to_db(ps, ref=np.max), y_axis='mel', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Pop music\n",
    "y, sr = librosa.load(r'C:\\Users\\Yang Saewon\\Desktop\\project\\myproject\\music_genre\\fma_small\\0/000010.wav', duration=10)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(librosa.power_to_db(ps, ref=np.max), y_axis='mel', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'librosa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8e0456ba0ba9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example of Rock music\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'C:\\Users\\Yang Saewon\\Desktop\\project\\myproject\\music_genre\\fma_small\\0/000255.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'librosa' is not defined"
     ]
    }
   ],
   "source": [
    "# Example of Rock music\n",
    "y, sr = librosa.load(r'C:\\Users\\Yang Saewon\\Desktop\\project\\myproject\\music_genre\\fma_small\\0/000255.wav', duration=10)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(librosa.power_to_db(ps, ref=np.max), y_axis='mel', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation (time stretch, pitch shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 0.8 \n",
    "\n",
    "for row in data.itertuples():\n",
    "    y, sr = librosa.load('C://Users/Yang Saewon/Desktop/project/music_genre/fma_small/' + row.path)  \n",
    "    y_changed = librosa.effects.time_stretch(y, rate=rate)\n",
    "    librosa.output.write_wav('C://Users/Yang Saewon/Desktop/project/music_genre/fma_small_augmented/' + row.path ,y_changed, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 0.9\n",
    "\n",
    "for row in data.itertuples():\n",
    "    y, sr = librosa.load('C://Users/Yang Saewon/Desktop/project/music_genre/fma_small/' + row.path)  \n",
    "    y_changed = librosa.effects.time_stretch(y, rate=rate)\n",
    "    librosa.output.write_wav('C://Users/Yang Saewon/Desktop/project/music_genre/fma_small_augmented2/' + row.path ,y_changed, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2 \n",
    "\n",
    "for row in data.itertuples():\n",
    "    y, sr = librosa.load('C://Users/Yang Saewon/Desktop/project/music_genre/fma_small/' + row.path)  \n",
    "    y_changed = librosa.effects.pitch_shift(y, sr, n_steps=n_steps)\n",
    "    librosa.output.write_wav('C://Users/Yang Saewon/Desktop/project/music_genre/fma_small_augmented1/' + row.path ,y_changed, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = -2 \n",
    "\n",
    "for row in data.itertuples():\n",
    "    y, sr = librosa.load('C:/Users/Yang Saewon/Desktop/project/myproject/music_genre/fma_small/' + row.path)  \n",
    "    y_changed = librosa.effects.pitch_shift(y, sr, n_steps=n_steps)\n",
    "    librosa.output.write_wav(r'C:/Users/Yang Saewon/Desktop/project/myproject/music_genre/fma_small_augmented3/' + row.path ,y_changed, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Rock music (original)\n",
    "y, sr = librosa.load(r'C:\\Users\\Yang Saewon\\Desktop\\project\\myproject\\music_genre\\fma_small\\0/000002.wav', duration=10)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " IPython.display.Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(librosa.power_to_db(ps, ref=np.max), y_axis='mel', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Rock music (time-stretch 0.8)\n",
    "y, sr = librosa.load(r'C:\\Users\\Yang Saewon\\Desktop\\project\\myproject\\music_genre\\fma_small_augmented\\0/000002.wav', duration=10)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(librosa.power_to_db(ps, ref=np.max), y_axis='mel', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Rock music (pitch-shift 2)\n",
    "y, sr = librosa.load(r'C:\\Users\\Yang Saewon\\Desktop\\project\\myproject\\music_genre\\fma_small_augmented1\\0/000002.wav', duration=10)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(librosa.power_to_db(ps, ref=np.max), y_axis='mel', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = [] # Dataset1\n",
    "\n",
    "for row in data.itertuples():\n",
    "    y, sr = librosa.load(r'C://Users/Yang Saewon/Desktop/project/myproject/music_genre/fma_small/' + row.path, duration=10)\n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    if ps.shape != (128, 431): continue\n",
    "    D1.append( (ps, row.genre_number) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D2 = [] # Dataset2 (time stretch 0.8)\n",
    "\n",
    "for row in data.itertuples():\n",
    "    y, sr = librosa.load(r'C://Users/Yang Saewon/Desktop/project/myproject/music_genre/fma_small_augmented/' + row.path, duration=10)\n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    if ps.shape != (128, 431): continue\n",
    "    D2.append( (ps, row.genre_number) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D3 = [] # Dataset3 (pitch shift 2)\n",
    "\n",
    "for row in data.itertuples():\n",
    "    y, sr = librosa.load(r'C://Users/Yang Saewon/Desktop/project/myproject/music_genre/fma_small_augmented1/' + row.path, duration=10)\n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    if ps.shape != (128, 431): continue\n",
    "    D3.append( (ps, row.genre_number) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D4 = [] # Dataset4 (time stretch 1.1)\n",
    "\n",
    "for row in data.itertuples():\n",
    "    y, sr = librosa.load(r'C://Users/Yang Saewon/Desktop/project/myproject/music_genre/fma_small_augmented2/' + row.path, duration=10)\n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    if ps.shape != (128, 431): continue\n",
    "    D4.append( (ps, row.genre_number) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D5 = [] # Dataset5 (pitch shift -2)\n",
    "\n",
    "for row in data.itertuples():\n",
    "    y, sr = librosa.load(r'C://Users/Yang Saewon/Desktop/project/myproject/music_genre/fma_small_augmented3/' + row.path, duration=10)\n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    if ps.shape != (128, 431): continue\n",
    "    D5.append( (ps, row.genre_number) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = D1 + D2 + D3 + D4 + D5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nu|mber of samples: \", len(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN을 활용한 Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = D\n",
    "random.shuffle(dataset)\n",
    "\n",
    "#train dev test split 8:1:1\n",
    "train = dataset[:32000]\n",
    "dev = dataset[32000:36000]\n",
    "test = dataset[36000:]\n",
    "\n",
    "X_train, Y_train = zip(*train)\n",
    "X_dev, Y_dev = zip(*dev)\n",
    "X_test, Y_test = zip(*test)\n",
    "\n",
    "# Reshape for CNN input\n",
    "X_train = np.array([x.reshape( (128, 431, 1) ) for x in X_train])\n",
    "X_dev = np.array([x.reshape( (128, 431, 1) ) for x in X_dev])\n",
    "X_test = np.array([x.reshape( (128, 431, 1) ) for x in X_test])\n",
    "\n",
    "# One-Hot encoding for classes\n",
    "Y_train = np.array(keras.utils.to_categorical(Y_train, 8))\n",
    "Y_dev = np.array(keras.utils.to_categorical(Y_dev, 8))\n",
    "Y_test = np.array(keras.utils.to_categorical(Y_test, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_shape=(128, 431, 1)\n",
    "\n",
    "model.add(Conv2D(24, (5, 5), strides=(1, 1), input_shape=input_shape))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.9\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with K.tf.device('/gpu:0'):\n",
    "    tb_hist = keras.callbacks.TensorBoard(log_dir='C:/Users/Yang Saewon/.keras/graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=2)\n",
    "    hist = model.fit(x=X_train, y=Y_train, epochs=epochs, batch_size=batch_size, validation_data= (X_dev, Y_dev), callbacks=[early_stopping, tb_hist]) \n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.legend(['loss','val_loss', 'acc','val_acc'])\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x=X_test, y=Y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#terminal에 텐서보드 실행\n",
    "tensorboard --logdir=\"C:/Users/Yang Saewon/.keras/graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.save('music_genre_classification.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "model = load_model('music_genre_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Test Data\n",
    "data = pd.read_csv(r'C:\\Users\\Yang Saewon\\Desktop\\project\\myproject\\music_genre\\music_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_number(i):\n",
    "    if i == 'Hip-Hop':\n",
    "        return 0\n",
    "    elif i == 'Pop':\n",
    "        return 1\n",
    "    elif i == 'Folk':\n",
    "        return 2\n",
    "    elif i == 'Rock':\n",
    "        return 3\n",
    "    elif i == 'Experimental':\n",
    "        return 4\n",
    "    elif i == 'International':\n",
    "        return 5\n",
    "    elif i == 'Electronic':\n",
    "        return 6\n",
    "    else:\n",
    "        return '7'\n",
    "    \n",
    "data['genre_number'] = data['genre'].apply(genre_number)\n",
    "data['file_name'] = data['file_name'].apply(lambda x: '{0:0>6}'.format(x))\n",
    "data['path'] = data['file_name'].astype('str') + \".wav\"\n",
    "data['path'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = [] # test dataset\n",
    "\n",
    "for row in data.itertuples():\n",
    "    y, sr = librosa.load(r'C:/Users/Yang Saewon/Desktop/project/myproject/music_genre/fma_small/0/' + row.path, duration=10)\n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    if ps.shape != (128, 431): continue\n",
    "    D.append( (ps, row.genre_number) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nu|mber of samples: \", len(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = D\n",
    "X_test, Y_test = zip(*test)\n",
    "X_test = np.array([x.reshape( (128, 431, 1) ) for x in X_test])\n",
    "Y_test = np.array(keras.utils.to_categorical(Y_test, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "yhat = model.predict_classes(X_test)\n",
    "\n",
    "for i in range(len(D)):\n",
    "    print('file_name: ' + data['file_name'][i] + ' True: ' + str(argmax(Y_test[i])) + ', Predict: ' + str(yhat[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
